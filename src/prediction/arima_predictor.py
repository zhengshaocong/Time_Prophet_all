# -*- coding: utf-8 -*-
"""
ARIMAé¢„æµ‹æ¨¡å—
æ”¯æŒå¤šå˜é‡é¢„æµ‹ï¼šå‡€èµ„é‡‘æµã€ç”³è´­é‡‘é¢ã€èµå›é‡‘é¢
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
from statsmodels.tsa.vector_ar.var_model import VAR

from utils.data_processor import DataProcessor
from utils.interactive_utils import print_header, print_success, print_error, print_info, print_warning
from config import DATA_DIR, OUTPUT_DIR, IMAGES_DIR, ARIMA_TRAINING_CONFIG
from utils.config_utils import get_field_name

# å¯¼å…¥ARIMAç›¸å…³æ¨¡å—
from .arima_model_trainer import ARIMAModelTrainer
from .arima_predictor_module import ARIMAPredictor
from .arima_visualization import ARIMAVisualizer
from .arima_visualization_enhanced import ARIMAVisualizationEnhanced


class ARIMAPredictorMain(DataProcessor):
    """ARIMAé¢„æµ‹å™¨ä¸»ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–ARIMAé¢„æµ‹å™¨"""
        super().__init__()
        self.module_name = "arima_predictor"
        self.time_series = None
        self.purchase_series = None
        self.redemption_series = None
        self.original_net_flow_series = None  # ä¿å­˜åŸå§‹å‡€èµ„é‡‘æµåºåˆ—
        self.original_purchase_series = None  # ä¿å­˜åŸå§‹ç”³è´­åºåˆ—
        self.original_redemption_series = None  # ä¿å­˜åŸå§‹èµå›åºåˆ—
        self.model = None
        self.purchase_model = None
        self.redemption_model = None
        # è‡ªç›¸å…³åˆ†æå»ºè®®å‚æ•°ï¼ˆç”¨äºæ”¶ç¼©æœç´¢èŒƒå›´ï¼‰
        self.suggested_p = None
        self.suggested_q = None
        self.predictions = None
        self.purchase_predictions = None
        self.redemption_predictions = None
        self.visualizer = ARIMAVisualizer()
        self.enhanced_visualizer = ARIMAVisualizationEnhanced()

    
    def load_data(self, file_path=None, use_data_processing=False, module_name=None):
        """é‡å†™load_dataæ–¹æ³•ï¼Œä¼˜å…ˆåŠ è½½é¢„å¤„ç†åçš„æ•°æ®"""
        try:
            # ä¼˜å…ˆå°è¯•åŠ è½½é¢„å¤„ç†åçš„æ•°æ®
            processed_data_files = list(OUTPUT_DIR.glob("data/*processed*.csv"))

            if processed_data_files:
                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œé€‰æ‹©æœ€æ–°çš„é¢„å¤„ç†æ•°æ®
                latest_file = max(processed_data_files, key=lambda x: x.stat().st_mtime)
                print_info(f"æ‰¾åˆ°é¢„å¤„ç†æ•°æ®æ–‡ä»¶: {latest_file}")

                # åŠ è½½é¢„å¤„ç†åçš„æ•°æ®
                self.data = pd.read_csv(latest_file, encoding='utf-8')
                print_success(f"é¢„å¤„ç†æ•°æ®åŠ è½½æˆåŠŸ: {len(self.data):,} æ¡è®°å½•")
                print_info(f"æ•°æ®åŒ…å« {len(self.data.columns)} ä¸ªç‰¹å¾")

                # æ˜¾ç¤ºå‰å‡ ä¸ªç‰¹å¾åˆ—å
                feature_columns = [col for col in self.data.columns if col not in ['user_id', 'report_date']]
                print_info(f"ç‰¹å¾åˆ—ç¤ºä¾‹: {feature_columns[:5]}")

                return True
            else:
                # å¦‚æœæ²¡æœ‰é¢„å¤„ç†æ•°æ®ï¼Œå°è¯•åŠ è½½åŸå§‹æ•°æ®
                data_file = DATA_DIR / "user_balance_table.csv"
                if not data_file.exists():
                    print_error(f"æœªæ‰¾åˆ°é¢„å¤„ç†æ•°æ®æˆ–åŸå§‹æ•°æ®æ–‡ä»¶")
                    print_info("è¯·å…ˆè¿è¡Œæ•°æ®é¢„å¤„ç†åŠŸèƒ½")
                    return False

                    
                print_info(f"åŠ è½½åŸå§‹æ•°æ®æ–‡ä»¶: {data_file}")
                self.data = pd.read_csv(data_file, encoding='utf-8')
                print_success(f"åŸå§‹æ•°æ®åŠ è½½æˆåŠŸ: {len(self.data):,} æ¡è®°å½•")
                return True

        except Exception as e:
            print_error(f"æ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False

    
    def _get_time_field_from_specialized_config(self):
        """ä»ç‰¹åŒ–é…ç½®æ–‡ä»¶è¯»å–æ—¶é—´å­—æ®µæ˜ å°„"""
        try:
            # æŸ¥æ‰¾ç‰¹åŒ–é…ç½®æ–‡ä»¶
            config_files = list(DATA_DIR.glob("*/config.json"))

            if not config_files:
                return None

            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„é…ç½®æ–‡ä»¶
            config_file = config_files[0]
            print_info(f"è¯»å–ç‰¹åŒ–é…ç½®æ–‡ä»¶: {config_file}")

            # è¯»å–é…ç½®æ–‡ä»¶
            import json
            with open(config_file, 'r', encoding='utf-8') as f:
                config = json.load(f)

            # è·å–æ—¶é—´å­—æ®µæ˜ å°„
            if 'field_mapping' in config and 'æ—¶é—´å­—æ®µ' in config['field_mapping']:
                time_field = config['field_mapping']['æ—¶é—´å­—æ®µ']
                print_success(f"ä»ç‰¹åŒ–é…ç½®è·å–æ—¶é—´å­—æ®µ: {time_field}")
                return time_field

            return None

        except Exception as e:
            print_warning(f"è¯»å–ç‰¹åŒ–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
            return None

    
    def prepare_data_for_arima(self, data_source=None):
        """ä¸ºARIMAæ¨¡å‹å‡†å¤‡æ•°æ®ï¼ˆæ”¯æŒå¤šå˜é‡é¢„æµ‹ï¼‰"""
        if self.data is None:
            print_error("è¯·å…ˆåŠ è½½æ•°æ®")
            return False

        print_header("ARIMAæ•°æ®å‡†å¤‡", "å¤šå˜é‡æ—¶é—´åºåˆ—å¤„ç†")

        try:
            # å°è¯•è·å–å­—æ®µå
            time_field = get_field_name("æ—¶é—´å­—æ®µ", data_source)
            purchase_field = get_field_name("ç”³è´­é‡‘é¢å­—æ®µ", data_source)
            redemption_field = get_field_name("èµå›é‡‘é¢å­—æ®µ", data_source)

            if not time_field:
                # å°è¯•ä»ç‰¹åŒ–é…ç½®æ–‡ä»¶è¯»å–å­—æ®µæ˜ å°„
                time_field = self._get_time_field_from_specialized_config()

                if not time_field:
                    print_error("ç¼ºå°‘æ—¶é—´å­—æ®µæ˜ å°„ï¼Œè¯·å…ˆè¿è¡ŒåŸºç¡€æ•°æ®åˆ†æ")
                    return False

            # ç¡®ä¿æ•°æ®å·²é¢„å¤„ç†
            if 'Net_Flow' not in self.data.columns:
                print("æ•°æ®æœªé¢„å¤„ç†ï¼Œæ­£åœ¨è‡ªåŠ¨é¢„å¤„ç†...")
                if not self.preprocess_data():
                    print_error("æ•°æ®é¢„å¤„ç†å¤±è´¥")
                    return False

            # è½¬æ¢æ—¶é—´å­—æ®µ
            self.data[time_field] = pd.to_datetime(self.data[time_field])

            # æŒ‰æ—¶é—´æ’åº
            self.data = self.data.sort_values(time_field)

            # æ£€æŸ¥å¿…è¦çš„å­—æ®µæ˜¯å¦å­˜åœ¨
            required_fields = ['Net_Flow', 'total_purchase_amt', 'total_redeem_amt']
            missing_fields = [field for field in required_fields if field not in self.data.columns]

            if missing_fields:
                print_error(f"ç¼ºå°‘å¿…è¦å­—æ®µ: {missing_fields}")
                print_info("è¯·ç¡®ä¿æ•°æ®é¢„å¤„ç†åŒ…å«ä»¥ä¸‹å­—æ®µ:")
                print_info("  - Net_Flow: å‡€èµ„é‡‘æµ")
                print_info("  - total_purchase_amt: ç”³è´­é‡‘é¢")
                print_info("  - total_redeem_amt: èµå›é‡‘é¢")
                return False

            # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
            print("=" * 50)
            print("ğŸš€ å¼€å§‹å‡†å¤‡å¤šå˜é‡æ—¶é—´åºåˆ—æ•°æ®...")
            print("=" * 50)
            print_info("å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®...")
            print(f"  ä½¿ç”¨æ—¶é—´å­—æ®µ: {time_field}")
            print(f"  ä½¿ç”¨å­—æ®µ: Net_Flow, total_purchase_amt, total_redeem_amt")

            # è®¾ç½®æ—¶é—´ç´¢å¼•
            data_temp = self.data.set_index(time_field)

            # åˆ›å»ºæ—¶é—´åºåˆ—
            net_flow_series = data_temp['Net_Flow'].dropna()
            purchase_series = data_temp['total_purchase_amt'].dropna()
            redemption_series = data_temp['total_redeem_amt'].dropna()

            # è¾“å‡ºæ•°æ®ä¿¡æ¯
            print(f"  æ•°æ®é‡: {len(self.data):,} æ¡")
            print(f"  æ—¶é—´åºåˆ—é•¿åº¦: {len(net_flow_series):,} æ¡")
            print(f"  æ—¶é—´èŒƒå›´: {net_flow_series.index.min()} ~ {net_flow_series.index.max()}")
            print(f"  å­—æ®µ: Net_Flow, total_purchase_amt, total_redeem_amt")
            print_info("å¤šå˜é‡æ—¶é—´åºåˆ—æ•°æ®å‡†å¤‡å®Œæˆ")

            # æ£€æŸ¥æ—¶é—´åºåˆ—çš„å¹³ç¨³æ€§
            print("æ£€æŸ¥æ—¶é—´åºåˆ—å¹³ç¨³æ€§...")

            # æ£€æŸ¥å‡€èµ„é‡‘æµå¹³ç¨³æ€§
            adf_result_net = adfuller(net_flow_series)
            print(f"å‡€èµ„é‡‘æµADFç»Ÿè®¡é‡: {adf_result_net[0]:.4f}, på€¼: {adf_result_net[1]:.4f}")

            # è¿›è¡Œè‡ªç›¸å…³åˆ†æ
            print("è¿›è¡Œè‡ªç›¸å…³åˆ†æ...")
            autocorr_result = self.visualizer.comprehensive_autocorrelation_analysis(net_flow_series)
            if autocorr_result:
                print(f"  å»ºè®®çš„ARIMAå‚æ•°: p={autocorr_result['suggested_p']}, q={autocorr_result['suggested_q']}")
                print(f"  åºåˆ—ç‰¹å¾: {autocorr_result['analysis_summary']['suggested_model']}")
                # è®°å½•å»ºè®®å‚æ•°ï¼Œåç»­ç”¨äºæ”¶ç¼©ç½‘æ ¼æœç´¢èŒƒå›´
                try:
                    self.suggested_p = int(autocorr_result.get('suggested_p'))
                except Exception:
                    self.suggested_p = None
                try:
                    self.suggested_q = int(autocorr_result.get('suggested_q'))
                except Exception:
                    self.suggested_q = None

            # æ£€æŸ¥ç”³è´­é‡‘é¢å¹³ç¨³æ€§
            adf_result_purchase = adfuller(purchase_series)
            print(f"ç”³è´­é‡‘é¢ADFç»Ÿè®¡é‡: {adf_result_purchase[0]:.4f}, på€¼: {adf_result_purchase[1]:.4f}")

            # æ£€æŸ¥èµå›é‡‘é¢å¹³ç¨³æ€§
            adf_result_redemption = adfuller(redemption_series)
            print(f"èµå›é‡‘é¢ADFç»Ÿè®¡é‡: {adf_result_redemption[0]:.4f}, på€¼: {adf_result_redemption[1]:.4f}")

            # ä¿å­˜åŸå§‹åºåˆ—
            self.original_net_flow_series = net_flow_series
            self.original_purchase_series = purchase_series
            self.original_redemption_series = redemption_series

            # å¤„ç†å¹³ç¨³æ€§
            if adf_result_net[1] <= 0.05:
                print_success("å‡€èµ„é‡‘æµæ—¶é—´åºåˆ—å¹³ç¨³")
                self.time_series = net_flow_series
            else:
                print_info("å‡€èµ„é‡‘æµæ—¶é—´åºåˆ—éå¹³ç¨³ï¼Œä½¿ç”¨ä¸€é˜¶å·®åˆ†")
                self.time_series = net_flow_series.diff().dropna()

            if adf_result_purchase[1] <= 0.05:
                print_success("ç”³è´­é‡‘é¢æ—¶é—´åºåˆ—å¹³ç¨³")
                self.purchase_series = purchase_series
            else:
                print_info("ç”³è´­é‡‘é¢æ—¶é—´åºåˆ—éå¹³ç¨³ï¼Œä½¿ç”¨ä¸€é˜¶å·®åˆ†")
                self.purchase_series = purchase_series.diff().dropna()

            if adf_result_redemption[1] <= 0.05:
                print_success("èµå›é‡‘é¢æ—¶é—´åºåˆ—å¹³ç¨³")
                self.redemption_series = redemption_series
            else:
                print_info("èµå›é‡‘é¢æ—¶é—´åºåˆ—éå¹³ç¨³ï¼Œä½¿ç”¨ä¸€é˜¶å·®åˆ†")
                self.redemption_series = redemption_series.diff().dropna()

            print(f"å‡€èµ„é‡‘æµæ—¶é—´åºåˆ—é•¿åº¦: {len(self.time_series)}")
            print(f"ç”³è´­é‡‘é¢æ—¶é—´åºåˆ—é•¿åº¦: {len(self.purchase_series)}")
            print(f"èµå›é‡‘é¢æ—¶é—´åºåˆ—é•¿åº¦: {len(self.redemption_series)}")

            return True

        except Exception as e:
            print_error(f"ARIMAæ•°æ®å‡†å¤‡å¤±è´¥: {e}")
            return False

    
    def train_arima_model(self):
        """è®­ç»ƒå¤šå˜é‡ARIMAæ¨¡å‹"""
        if self.time_series is None or self.purchase_series is None or self.redemption_series is None:
            print_error("è¯·å…ˆå‡†å¤‡æ•°æ®")
            return False

        print_header("å¤šå˜é‡ARIMAæ¨¡å‹è®­ç»ƒ", "å‚æ•°é€‰æ‹©ä¸æ¨¡å‹è®­ç»ƒ")

        try:
            # è®­ç»ƒå‡€èµ„é‡‘æµæ¨¡å‹
            print("è®­ç»ƒå‡€èµ„é‡‘æµARIMAæ¨¡å‹...")
            # å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆï¼Œé€‰æ‹©AICæœ€å°çš„
            best_aic = float('inf')
            best_model = None
            best_params = None

            # ä»é…ç½®æ–‡ä»¶è·å–å‚æ•°èŒƒå›´
            model_config = ARIMA_TRAINING_CONFIG["æ¨¡å‹å‚æ•°"]["ARIMAå‚æ•°"]
            p_values = model_config["p_range"]
            d_values = model_config["d_range"]
            q_values = model_config["q_range"]

            print(f"ä½¿ç”¨é…ç½®çš„å‚æ•°èŒƒå›´: p={p_values}, d={d_values}, q={q_values}")

            # è‹¥æœ‰è‡ªç›¸å…³åˆ†æçš„å»ºè®®å€¼ï¼Œåˆ™ä»¥å»ºè®®å€¼ä¸ºä¸­å¿ƒæ”¶ç¼©p/qèŒƒå›´
            try:
                if self.suggested_p is not None:
                    candidate_p = sorted(set([max(0, self.suggested_p - 1), self.suggested_p, self.suggested_p + 1]))
                    narrowed_p = [v for v in candidate_p if v in p_values]
                    if narrowed_p:
                        p_values = narrowed_p
                if self.suggested_q is not None:
                    candidate_q = sorted(set([max(0, self.suggested_q - 1), self.suggested_q, self.suggested_q + 1]))
                    narrowed_q = [v for v in candidate_q if v in q_values]
                    if narrowed_q:
                        q_values = narrowed_q
                if (self.suggested_p is not None) or (self.suggested_q is not None):
                    print(f"ç»“åˆè‡ªç›¸å…³åˆ†æåçš„å‚æ•°èŒƒå›´: p={p_values}, q={q_values}")
            except Exception as _:
                # é‡åˆ°å¼‚å¸¸åˆ™ä¿æŒåŸèŒƒå›´ï¼Œé¿å…å½±å“å·²æœ‰æµç¨‹
                pass

            for p in p_values:
                for d in d_values:
                    for q in q_values:
                        try:
                            model = ARIMA(self.time_series, order=(p, d, q))
                            fitted_model = model.fit()
                            if fitted_model.aic < best_aic:
                                best_aic = fitted_model.aic
                                best_model = fitted_model
                                best_params = (p, d, q)
                        except:
                            continue

            if best_model is None:
                # å¦‚æœç½‘æ ¼æœç´¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
                print("ç½‘æ ¼æœç´¢å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°")
                self.model = ARIMA(self.time_series, order=(1, 1, 1)).fit()
            else:
                self.model = best_model
                print(f"å‡€èµ„é‡‘æµæœ€ä½³å‚æ•°: {best_params}, AIC: {best_aic:.4f}")

            # è®­ç»ƒç”³è´­é‡‘é¢æ¨¡å‹
            print("è®­ç»ƒç”³è´­é‡‘é¢ARIMAæ¨¡å‹...")
            best_aic_purchase = float('inf')
            best_model_purchase = None
            best_params_purchase = None

            for p in p_values:
                for d in d_values:
                    for q in q_values:
                        try:
                            model = ARIMA(self.purchase_series, order=(p, d, q))
                            fitted_model = model.fit()
                            if fitted_model.aic < best_aic_purchase:
                                best_aic_purchase = fitted_model.aic
                                best_model_purchase = fitted_model
                                best_params_purchase = (p, d, q)
                        except:
                            continue

            if best_model_purchase is None:
                self.purchase_model = ARIMA(self.purchase_series, order=(1, 1, 1)).fit()
            else:
                self.purchase_model = best_model_purchase
                print(f"ç”³è´­é‡‘é¢æœ€ä½³å‚æ•°: {best_params_purchase}, AIC: {best_aic_purchase:.4f}")

            # è®­ç»ƒèµå›é‡‘é¢æ¨¡å‹
            print("è®­ç»ƒèµå›é‡‘é¢ARIMAæ¨¡å‹...")
            best_aic_redemption = float('inf')
            best_model_redemption = None
            best_params_redemption = None

            for p in p_values:
                for d in d_values:
                    for q in q_values:
                        try:
                            model = ARIMA(self.redemption_series, order=(p, d, q))
                            fitted_model = model.fit()
                            if fitted_model.aic < best_aic_redemption:
                                best_aic_redemption = fitted_model.aic
                                best_model_redemption = fitted_model
                                best_params_redemption = (p, d, q)
                        except:
                            continue

            if best_model_redemption is None:
                self.redemption_model = ARIMA(self.redemption_series, order=(1, 1, 1)).fit()
            else:
                self.redemption_model = best_model_redemption
                print(f"èµå›é‡‘é¢æœ€ä½³å‚æ•°: {best_params_redemption}, AIC: {best_aic_redemption:.4f}")

            print_success("å¤šå˜é‡ARIMAæ¨¡å‹è®­ç»ƒå®Œæˆ")

            # è¿›è¡Œæ®‹å·®è‡ªç›¸å…³æ£€éªŒ
            print("è¿›è¡Œæ®‹å·®è‡ªç›¸å…³æ£€éªŒ...")
            if self.model:
                residuals = self.model.resid
                residual_test = self.visualizer.residual_autocorrelation_test(residuals)
                if residual_test:
                    print(f"  æ®‹å·®è´¨é‡: {'è‰¯å¥½' if residual_test['is_white_noise'] else 'éœ€è¦æ”¹è¿›'}")

            return True

        except Exception as e:
            print_error(f"ARIMAæ¨¡å‹è®­ç»ƒå¤±è´¥: {e}")
            return False

    
    def make_predictions(self, steps=None):
        """è¿›è¡Œå¤šå˜é‡é¢„æµ‹"""
        if self.model is None or self.purchase_model is None or self.redemption_model is None:
            print_error("è¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return False

        if steps is None:
            steps = ARIMA_TRAINING_CONFIG["é¢„æµ‹é…ç½®"]["é¢„æµ‹æ­¥æ•°"]  # ä»é…ç½®æ–‡ä»¶è¯»å–é¢„æµ‹æ­¥æ•°

        print_header("å¤šå˜é‡ARIMAé¢„æµ‹", f"é¢„æµ‹æœªæ¥{steps}å¤©")

        try:
            # é¢„æµ‹å‡€èµ„é‡‘æµ
            print("é¢„æµ‹å‡€èµ„é‡‘æµ...")
            net_flow_forecast = self.model.forecast(steps=steps)

            # æ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨ï¼Œé¿å…è¿‡äºå¹³ç¨³
            np.random.seed(42)  # è®¾ç½®éšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§
            noise_ratio = ARIMA_TRAINING_CONFIG.get("é¢„æµ‹é…ç½®", {}).get("å™ªå£°æ¯”ä¾‹", 0.1)  # ä»é…ç½®æ–‡ä»¶è¯»å–å™ªå£°æ¯”ä¾‹
            noise_scale = net_flow_forecast.std() * noise_ratio
            noise = np.random.normal(0, noise_scale, len(net_flow_forecast))
            net_flow_forecast = net_flow_forecast + noise

            # å¦‚æœå‡€èµ„é‡‘æµä½¿ç”¨äº†å·®åˆ†ï¼Œéœ€è¦è¿˜åŸ
            if len(self.time_series) != len(self.original_net_flow_series):
                print("å‡€èµ„é‡‘æµä½¿ç”¨äº†å·®åˆ†ï¼Œæ­£åœ¨è¿˜åŸ...")
                last_original_value = self.original_net_flow_series.iloc[-1]
                net_flow_forecast = net_flow_forecast.cumsum() + last_original_value
                print(f"è¿˜åŸåå‡€èµ„é‡‘æµé¢„æµ‹å€¼èŒƒå›´: {net_flow_forecast.min():.2f} åˆ° {net_flow_forecast.max():.2f}")

            # é¢„æµ‹ç”³è´­é‡‘é¢
            print("é¢„æµ‹ç”³è´­é‡‘é¢...")
            print(f"ç”³è´­é‡‘é¢æ—¶é—´åºåˆ—é•¿åº¦: {len(self.purchase_series)}")
            print(f"ç”³è´­é‡‘é¢æ—¶é—´åºåˆ—èŒƒå›´: {self.purchase_series.min():.2f} åˆ° {self.purchase_series.max():.2f}")
            print(f"ç”³è´­é‡‘é¢æ—¶é—´åºåˆ—å‡å€¼: {self.purchase_series.mean():.2f}")
            purchase_forecast = self.purchase_model.forecast(steps=steps)

            # æ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨ï¼Œé¿å…è¿‡äºå¹³ç¨³
            noise_ratio_purchase = ARIMA_TRAINING_CONFIG.get("é¢„æµ‹é…ç½®", {}).get("ç”³è´­å™ªå£°æ¯”ä¾‹", 0.15)  # ä»é…ç½®æ–‡ä»¶è¯»å–ç”³è´­å™ªå£°æ¯”ä¾‹
            noise_scale_purchase = purchase_forecast.std() * noise_ratio_purchase
            noise_purchase = np.random.normal(0, noise_scale_purchase, len(purchase_forecast))
            purchase_forecast = purchase_forecast + noise_purchase

            print(f"ç”³è´­é‡‘é¢é¢„æµ‹å€¼èŒƒå›´: {purchase_forecast.min():.2f} åˆ° {purchase_forecast.max():.2f}")
            print(f"ç”³è´­é‡‘é¢é¢„æµ‹å€¼å‡å€¼: {purchase_forecast.mean():.2f}")

            # å¦‚æœç”³è´­é‡‘é¢ä½¿ç”¨äº†å·®åˆ†ï¼Œéœ€è¦è¿˜åŸ
            if len(self.purchase_series) != len(self.original_purchase_series):
                print("ç”³è´­é‡‘é¢ä½¿ç”¨äº†å·®åˆ†ï¼Œæ­£åœ¨è¿˜åŸ...")
                last_original_value = self.original_purchase_series.iloc[-1]
                purchase_forecast = purchase_forecast.cumsum() + last_original_value
                print(f"è¿˜åŸåç”³è´­é‡‘é¢é¢„æµ‹å€¼èŒƒå›´: {purchase_forecast.min():.2f} åˆ° {purchase_forecast.max():.2f}")

            # é¢„æµ‹èµå›é‡‘é¢
            print("é¢„æµ‹èµå›é‡‘é¢...")
            print(f"èµå›é‡‘é¢æ—¶é—´åºåˆ—é•¿åº¦: {len(self.redemption_series)}")
            print(f"èµå›é‡‘é¢æ—¶é—´åºåˆ—èŒƒå›´: {self.redemption_series.min():.2f} åˆ° {self.redemption_series.max():.2f}")
            print(f"èµå›é‡‘é¢æ—¶é—´åºåˆ—å‡å€¼: {self.redemption_series.mean():.2f}")
            redemption_forecast = self.redemption_model.forecast(steps=steps)

            # æ·»åŠ æ›´å¤šçš„éšæœºæ³¢åŠ¨ï¼Œé¿å…è¿‡äºå¹³ç¨³
            noise_ratio_redemption = ARIMA_TRAINING_CONFIG.get("é¢„æµ‹é…ç½®", {}).get("èµå›å™ªå£°æ¯”ä¾‹", 0.25)  # å¢åŠ å™ªå£°æ¯”ä¾‹
            noise_scale_redemption = redemption_forecast.std() * noise_ratio_redemption
            if noise_scale_redemption == 0 or np.isnan(noise_scale_redemption):
                # å¦‚æœæ ‡å‡†å·®ä¸º0æˆ–NaNï¼Œä½¿ç”¨åŸå§‹æ•°æ®çš„æ ‡å‡†å·®
                noise_scale_redemption = self.original_redemption_series.std() * 0.1

            noise_redemption = np.random.normal(0, noise_scale_redemption, len(redemption_forecast))
            redemption_forecast = redemption_forecast + noise_redemption

            print(f"èµå›é‡‘é¢é¢„æµ‹å€¼èŒƒå›´: {redemption_forecast.min():.2f} åˆ° {redemption_forecast.max():.2f}")
            print(f"èµå›é‡‘é¢é¢„æµ‹å€¼å‡å€¼: {redemption_forecast.mean():.2f}")

            # å¦‚æœèµå›é‡‘é¢ä½¿ç”¨äº†å·®åˆ†ï¼Œéœ€è¦è¿˜åŸ
            if len(self.redemption_series) != len(self.original_redemption_series):
                print("èµå›é‡‘é¢ä½¿ç”¨äº†å·®åˆ†ï¼Œæ­£åœ¨è¿˜åŸ...")
                last_original_value = self.original_redemption_series.iloc[-1]

                # æ”¹è¿›çš„å·®åˆ†è¿˜åŸé€»è¾‘
                redemption_forecast_cumsum = redemption_forecast.cumsum()
                redemption_forecast = redemption_forecast_cumsum + last_original_value

                # ç¡®ä¿è¿˜åŸåçš„å€¼åœ¨åˆç†èŒƒå›´å†…
                min_redemption = self.original_redemption_series.min() * 0.5
                max_redemption = self.original_redemption_series.max() * 1.5
                redemption_forecast = np.clip(redemption_forecast, min_redemption, max_redemption)

                print(f"è¿˜åŸåèµå›é‡‘é¢é¢„æµ‹å€¼èŒƒå›´: {redemption_forecast.min():.2f} åˆ° {redemption_forecast.max():.2f}")
            else:
                # å¦‚æœæ²¡æœ‰ä½¿ç”¨å·®åˆ†ï¼Œä¹Ÿæ·»åŠ ä¸€äº›éšæœºæ³¢åŠ¨
                print("èµå›é‡‘é¢æœªä½¿ç”¨å·®åˆ†ï¼Œæ·»åŠ éšæœºæ³¢åŠ¨...")
                # æ·»åŠ åŸºäºåŸå§‹æ•°æ®æ ‡å‡†å·®çš„éšæœºæ³¢åŠ¨
                original_std = self.original_redemption_series.std()
                additional_noise = np.random.normal(0, original_std * 0.1, len(redemption_forecast))
                redemption_forecast = redemption_forecast + additional_noise

                # ç¡®ä¿é¢„æµ‹å€¼åœ¨åˆç†èŒƒå›´å†…
                min_redemption = self.original_redemption_series.min() * 0.5
                max_redemption = self.original_redemption_series.max() * 1.5
                redemption_forecast = np.clip(redemption_forecast, min_redemption, max_redemption)

                print(f"æ·»åŠ æ³¢åŠ¨åèµå›é‡‘é¢é¢„æµ‹å€¼èŒƒå›´: {redemption_forecast.min():.2f} åˆ° {redemption_forecast.max():.2f}")

            # åˆ›å»ºé¢„æµ‹ç»“æœæ•°æ®æ¡†
            last_date = self.time_series.index[-1]
            future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=steps, freq='D')

            self.predictions = pd.Series(net_flow_forecast, index=future_dates)
            self.purchase_predictions = pd.Series(purchase_forecast, index=future_dates)
            self.redemption_predictions = pd.Series(redemption_forecast, index=future_dates)

            print_success("å¤šå˜é‡é¢„æµ‹å®Œæˆ")
            print(f"å‡€èµ„é‡‘æµé¢„æµ‹èŒƒå›´: {self.predictions.index[0].date()} åˆ° {self.predictions.index[-1].date()}")
            print(f"ç”³è´­é‡‘é¢é¢„æµ‹èŒƒå›´: {self.purchase_predictions.index[0].date()} åˆ° {self.purchase_predictions.index[-1].date()}")
            print(f"èµå›é‡‘é¢é¢„æµ‹èŒƒå›´: {self.redemption_predictions.index[0].date()} åˆ° {self.redemption_predictions.index[-1].date()}")

            return True

        except Exception as e:
            print_error(f"é¢„æµ‹å¤±è´¥: {e}")
            return False

    
    def save_results(self):
        """ä¿å­˜å¤šå˜é‡é¢„æµ‹ç»“æœ"""
        if (self.predictions is None or self.purchase_predictions is None or 
            self.redemption_predictions is None):
            print_error("æ²¡æœ‰é¢„æµ‹ç»“æœå¯ä¿å­˜")
            return False

        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = OUTPUT_DIR / "data"
            output_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜é¢„æµ‹ç»“æœ
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            predictions_file = output_dir / f"multi_arima_predictions_{timestamp}.csv"

            # åˆ›å»ºç»“æœæ•°æ®æ¡†
            results_df = pd.DataFrame({
                'é¢„æµ‹æ—¥æœŸ': self.predictions.index,
                'å‡€èµ„é‡‘æµé¢„æµ‹å€¼': self.predictions.values,
                'ç”³è´­é‡‘é¢é¢„æµ‹å€¼': self.purchase_predictions.values,
                'èµå›é‡‘é¢é¢„æµ‹å€¼': self.redemption_predictions.values
            })

            # ä¿å­˜åˆ°æ–‡ä»¶
            results_df.to_csv(predictions_file, index=False, encoding='utf-8')
            print_success(f"å¤šå˜é‡é¢„æµ‹ç»“æœå·²ä¿å­˜: {predictions_file}")

            return True

        except Exception as e:
            print_error(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")
            return False

    
    def generate_enhanced_visualizations(self):
        """ç”Ÿæˆå¢å¼ºçš„å¤šå˜é‡å¯è§†åŒ–å›¾è¡¨"""
        if (self.predictions is None or self.purchase_predictions is None or 
            self.redemption_predictions is None or self.data is None):
            print_error("æ²¡æœ‰é¢„æµ‹ç»“æœæˆ–æ•°æ®å¯å¯è§†åŒ–")
            return False

        print_header("ç”Ÿæˆå¢å¼ºå¤šå˜é‡å¯è§†åŒ–å›¾è¡¨", "ç”³è´­èµå›å‡€èµ„é‡‘æµé¢„æµ‹ç»“æœ")

        try:
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = IMAGES_DIR / "arima"
            output_dir.mkdir(parents=True, exist_ok=True)

            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # 1. ç”Ÿæˆå¤šå˜é‡ç»¼åˆé¢„æµ‹å›¾
            print_info("ç”Ÿæˆå¤šå˜é‡ç»¼åˆé¢„æµ‹å›¾...")
            comprehensive_file = output_dir / f"multi_comprehensive_predictions_{timestamp}.png"
            self._plot_multi_variable_predictions(comprehensive_file)

            # 2. ç”Ÿæˆå¤šå˜é‡é¢„æµ‹æ‘˜è¦å›¾
            print_info("ç”Ÿæˆå¤šå˜é‡é¢„æµ‹æ‘˜è¦å›¾...")
            summary_file = output_dir / f"multi_prediction_summary_{timestamp}.png"
            self._plot_multi_variable_summary(summary_file)

            print_success("å¢å¼ºå¤šå˜é‡å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆå®Œæˆ")
            return True

        except Exception as e:
            print_error(f"ç”Ÿæˆå¢å¼ºå¤šå˜é‡å¯è§†åŒ–å›¾è¡¨å¤±è´¥: {e}")
            return False

    
    def _plot_multi_variable_predictions(self, save_path):
        """ç»˜åˆ¶å¤šå˜é‡é¢„æµ‹å›¾"""
        try:
            import matplotlib.pyplot as plt
            from utils.visualization_utils import setup_matplotlib

            setup_matplotlib()

            fig, axes = plt.subplots(3, 1, figsize=(15, 12))
            fig.suptitle('å¤šå˜é‡ARIMAé¢„æµ‹ç»“æœ', fontsize=16, fontweight='bold')

            # 1. å‡€èµ„é‡‘æµé¢„æµ‹
            time_field = get_field_name("æ—¶é—´å­—æ®µ")
            original_net_flow = self.data.groupby(time_field)['Net_Flow'].sum()

            axes[0].plot(original_net_flow.index, original_net_flow.values, 
                        label='å®é™…å‡€èµ„é‡‘æµ', color='blue', linewidth=2, alpha=0.8)
            axes[0].plot(self.predictions.index, self.predictions.values, 
                        label='é¢„æµ‹å‡€èµ„é‡‘æµ', color='red', linewidth=2, linestyle='--')
            axes[0].set_title('å‡€èµ„é‡‘æµé¢„æµ‹', fontsize=14, fontweight='bold')
            axes[0].set_xlabel('æ—¶é—´')
            axes[0].set_ylabel('å‡€èµ„é‡‘æµ')
            axes[0].legend()
            axes[0].grid(True, alpha=0.3)

            # 2. ç”³è´­é‡‘é¢é¢„æµ‹
            original_purchase = self.data.groupby(time_field)['total_purchase_amt'].sum()

            axes[1].plot(original_purchase.index, original_purchase.values, 
                        label='å®é™…ç”³è´­é‡‘é¢', color='green', linewidth=2, alpha=0.8)
            axes[1].plot(self.purchase_predictions.index, self.purchase_predictions.values, 
                        label='é¢„æµ‹ç”³è´­é‡‘é¢', color='darkgreen', linewidth=2, linestyle='--')
            axes[1].set_title('ç”³è´­é‡‘é¢é¢„æµ‹', fontsize=14, fontweight='bold')
            axes[1].set_xlabel('æ—¶é—´')
            axes[1].set_ylabel('ç”³è´­é‡‘é¢')
            axes[1].legend()
            axes[1].grid(True, alpha=0.3)

            # 3. èµå›é‡‘é¢é¢„æµ‹
            original_redemption = self.data.groupby(time_field)['total_redeem_amt'].sum()

            axes[2].plot(original_redemption.index, original_redemption.values, 
                        label='å®é™…èµå›é‡‘é¢', color='orange', linewidth=2, alpha=0.8)
            axes[2].plot(self.redemption_predictions.index, self.redemption_predictions.values, 
                        label='é¢„æµ‹èµå›é‡‘é¢', color='darkorange', linewidth=2, linestyle='--')
            axes[2].set_title('èµå›é‡‘é¢é¢„æµ‹', fontsize=14, fontweight='bold')
            axes[2].set_xlabel('æ—¶é—´')
            axes[2].set_ylabel('èµå›é‡‘é¢')
            axes[2].legend()
            axes[2].grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()

            print_success(f"å¤šå˜é‡é¢„æµ‹å›¾å·²ä¿å­˜: {save_path}")

        except Exception as e:
            print_error(f"ç»˜åˆ¶å¤šå˜é‡é¢„æµ‹å›¾å¤±è´¥: {e}")

    
    def _plot_multi_variable_summary(self, save_path):
        """ç»˜åˆ¶å¤šå˜é‡é¢„æµ‹æ‘˜è¦å›¾"""
        try:
            import matplotlib.pyplot as plt
            from utils.visualization_utils import setup_matplotlib

            setup_matplotlib()

            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle('å¤šå˜é‡ARIMAé¢„æµ‹æ‘˜è¦', fontsize=16, fontweight='bold')

            # 1. é¢„æµ‹å€¼å¯¹æ¯”
            axes[0, 0].plot(self.predictions.index, self.predictions.values, 
                           label='å‡€èµ„é‡‘æµ', color='blue', linewidth=2)
            axes[0, 0].plot(self.purchase_predictions.index, self.purchase_predictions.values, 
                           label='ç”³è´­é‡‘é¢', color='green', linewidth=2)
            axes[0, 0].plot(self.redemption_predictions.index, self.redemption_predictions.values, 
                           label='èµå›é‡‘é¢', color='orange', linewidth=2)
            axes[0, 0].set_title('é¢„æµ‹å€¼å¯¹æ¯”', fontsize=12)
            axes[0, 0].set_xlabel('æ—¶é—´')
            axes[0, 0].set_ylabel('é‡‘é¢')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)

            # 2. é¢„æµ‹ç»Ÿè®¡ä¿¡æ¯
            stats_text = f"å‡€èµ„é‡‘æµé¢„æµ‹ç»Ÿè®¡:\n"
            stats_text += f"  å‡å€¼: {self.predictions.mean():.2f}\n"
            stats_text += f"  æ ‡å‡†å·®: {self.predictions.std():.2f}\n"
            stats_text += f"  æœ€å¤§å€¼: {self.predictions.max():.2f}\n"
            stats_text += f"  æœ€å°å€¼: {self.predictions.min():.2f}\n\n"
            stats_text += f"ç”³è´­é‡‘é¢é¢„æµ‹ç»Ÿè®¡:\n"
            stats_text += f"  å‡å€¼: {self.purchase_predictions.mean():.2f}\n"
            stats_text += f"  æ ‡å‡†å·®: {self.purchase_predictions.std():.2f}\n"
            stats_text += f"  æœ€å¤§å€¼: {self.purchase_predictions.max():.2f}\n"
            stats_text += f"  æœ€å°å€¼: {self.purchase_predictions.min():.2f}"

            axes[0, 1].text(0.05, 0.95, stats_text, transform=axes[0, 1].transAxes, 
                           fontsize=10, verticalalignment='top',
                           bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
            axes[0, 1].set_title('é¢„æµ‹ç»Ÿè®¡ä¿¡æ¯', fontsize=12)
            axes[0, 1].axis('off')

            # 3. å‡€èµ„é‡‘æµè¶‹åŠ¿åˆ†æ
            axes[1, 0].plot(self.predictions.index, self.predictions.values, 
                           color='blue', linewidth=2, label='å‡€èµ„é‡‘æµè¶‹åŠ¿')
            axes[1, 0].axhline(y=0, color='red', linestyle='--', alpha=0.7, label='é›¶çº¿')
            axes[1, 0].set_title('å‡€èµ„é‡‘æµè¶‹åŠ¿åˆ†æ', fontsize=12)
            axes[1, 0].set_xlabel('æ—¶é—´')
            axes[1, 0].set_ylabel('å‡€èµ„é‡‘æµ')
            axes[1, 0].legend()
            axes[1, 0].grid(True, alpha=0.3)

            # 4. ç”³è´­èµå›æ¯”ä¾‹
            ratio = self.purchase_predictions / (self.purchase_predictions + self.redemption_predictions)
            axes[1, 1].plot(self.predictions.index, ratio, 
                           color='purple', linewidth=2, label='ç”³è´­æ¯”ä¾‹')
            axes[1, 1].axhline(y=0.5, color='red', linestyle='--', alpha=0.7, label='50%çº¿')
            axes[1, 1].set_title('ç”³è´­èµå›æ¯”ä¾‹è¶‹åŠ¿', fontsize=12)
            axes[1, 1].set_xlabel('æ—¶é—´')
            axes[1, 1].set_ylabel('ç”³è´­æ¯”ä¾‹')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)

            plt.tight_layout()
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()

            print_success(f"å¤šå˜é‡é¢„æµ‹æ‘˜è¦å›¾å·²ä¿å­˜: {save_path}")

        except Exception as e:
            print_error(f"ç»˜åˆ¶å¤šå˜é‡é¢„æµ‹æ‘˜è¦å›¾å¤±è´¥: {e}")

    
    def run_full_arima_analysis(self):
        """è¿è¡Œå®Œæ•´çš„å¤šå˜é‡ARIMAåˆ†ææµç¨‹"""
        print_header("å®Œæ•´å¤šå˜é‡ARIMAåˆ†æ", "æ•°æ®å‡†å¤‡ -> æ¨¡å‹è®­ç»ƒ -> é¢„æµ‹ -> å¯è§†åŒ–")

        try:
            # 1. å‡†å¤‡æ•°æ®
            if not self.prepare_data_for_arima():
                return False

            # 2. è®­ç»ƒæ¨¡å‹
            if not self.train_arima_model():
                return False

            # 3. è¿›è¡Œé¢„æµ‹
            if not self.make_predictions():
                return False

            # 4. ä¿å­˜ç»“æœ
            if not self.save_results():
                return False

            # 5. ç”Ÿæˆå¢å¼ºå¯è§†åŒ–
            if not self.generate_enhanced_visualizations():
                return False

            print_success("å®Œæ•´å¤šå˜é‡ARIMAåˆ†ææµç¨‹æ‰§è¡Œå®Œæˆï¼")
            return True

        except Exception as e:
            print_error(f"å¤šå˜é‡ARIMAåˆ†æå¤±è´¥: {e}")
            return False



def run_arima_prediction():
    """è¿è¡Œå¤šå˜é‡ARIMAé¢„æµ‹åˆ†æ"""
    print_header("å¤šå˜é‡ARIMAé¢„æµ‹", "å‡€èµ„é‡‘æµã€ç”³è´­é‡‘é¢ã€èµå›é‡‘é¢é¢„æµ‹")

    # åˆ›å»ºARIMAé¢„æµ‹å™¨å®ä¾‹
    predictor = ARIMAPredictorMain()

    # åŠ è½½æ•°æ®
    if not predictor.load_data():
        print_error("æ•°æ®åŠ è½½å¤±è´¥")
        return False

    # è¿è¡Œå®Œæ•´çš„å¤šå˜é‡ARIMAåˆ†æ
    success = predictor.run_full_arima_analysis()

    if success:
        print_success("å¤šå˜é‡ARIMAé¢„æµ‹åˆ†æå®Œæˆï¼")
        print_info("é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ°è¾“å‡ºç›®å½•")
    else:
        print_error("å¤šå˜é‡ARIMAé¢„æµ‹åˆ†æå¤±è´¥")

    return success
