# 资金流预测系统 (Time Prophet)

这是一个基于时间序列的资金流预测系统，能够分析历史资金流数据并进行未来趋势预测。

## 项目功能

### 1. 基础数据分析
- **数据读取和解析**: 读取CSV数据文件，解析字段信息
- **数据可视化**: 生成时间序列图、分布图、箱线图、热力图等
- **数据摘要**: 提供数据统计信息和字段分析报告
- **数据源配置生成**: 自动检测数据字段并生成数据源特定的配置文件

### 2. 数据预处理
- **数据清洗和验证**: 自动处理缺失值和异常值
- **特征工程**: 时间特征提取和特征转换
- **异常值检测和处理**: 基于统计方法的异常值处理
- **数据聚合**: 支持按时间字段进行数据聚合，支持日、周、月聚合方式

#### 数据聚合功能
数据聚合功能集成在数据清洗阶段，通过配置文件控制：

**配置位置**: `config/data_processing.py` 中的 `DATA_PREPROCESSING_CONFIG["数据聚合"]`

**配置选项**:
```python
"数据聚合": {
    "启用聚合": True,          # 是否启用数据聚合
    "聚合方式": "daily",        # 聚合方式: daily(日), weekly(周), monthly(月)
    "聚合函数": "sum",          # 聚合函数: sum, mean, median, max, min
    "时间字段": "auto",         # 时间字段名称，auto表示自动检测
    "聚合字段": "auto",         # 聚合字段列表，auto表示自动检测数值字段
    "排除字段": ["user_id"],    # 排除的字段列表
    "处理缺失值": True,         # 是否处理聚合后的缺失值
    "缺失值填充": 0,            # 缺失值填充方式
    "输出格式": {
        "保留时间索引": False,   # 是否保留时间索引
        "重置索引": True        # 是否重置索引
    }
}
```

**聚合提示功能**:
系统现在提供了详细的聚合状态提示，帮助你判断是否使用了聚合功能：

1. **聚合启用状态提示**:
   - 🔄 聚合功能已启用/已禁用
   - 📅 聚合方式 (daily/weekly/monthly)
   - 🧮 聚合函数 (sum/mean/median/max/min)
   - 🕒 时间字段 (自动检测或手动指定)

2. **聚合执行过程提示**:
   - 🔍 自动检测到的数值字段数量
   - 🚀 聚合操作开始执行
   - 🔧 缺失值处理状态
   - 🔄 时间索引重置状态

3. **聚合结果总结**:
   - ✅ 聚合成功: 显示数据量变化和减少比例
   - ⚠️ 聚合未生效: 提示可能的原因和建议
   - ❌ 聚合失败: 显示错误信息和解决建议

4. **聚合状态总结**:
   ```
   📊 【聚合状态总结】
     原始数据量: 1,000 条
     聚合后数据量: 100 条
     数据减少: 900 条 (90.0%)
     聚合方式: daily | 聚合函数: sum
     ✅ 聚合功能已成功执行
   ```

**使用场景**:
- **时间序列预测**: 将高频数据聚合为日、周、月级别，适合ARIMA等时间序列模型
- **数据降维**: 减少数据量，提高处理效率
- **业务分析**: 按时间维度汇总业务指标

**启用方法**:
1. 编辑 `config/data_processing.py`
2. 设置 `"启用聚合": True`
3. 选择聚合方式和聚合函数
4. 运行数据预处理功能

**聚合提示示例**:
```
🔄 聚合功能已启用
📅 聚合方式: daily
🧮 聚合函数: sum
🕒 时间字段: auto
🔍 自动检测到 5 个数值字段用于聚合
🚀 开始执行聚合操作...
🔧 已处理聚合后的缺失值 (填充值: 0)
🔄 已重置时间索引
✅ 聚合完成: 1,000 -> 100 条 (减少 90.0%)
✅ 聚合操作完成!
```

### 3. ARIMA预测
- **ARIMA预测**: 使用ARIMA模型进行时间序列预测
- **预测结果可视化**: 预测结果图表展示
- **模型评估**: 预测模型性能评估

### 4. 经典分解法预测
- **经典分解法**: 使用传统的时间序列分解方法进行预测
- **周期因子分析**: 自动识别和计算周期性模式（周度、月度、年度）
- **Base值计算**: 去除周期影响的基础值计算
- **分解可视化**: 趋势项、周期项、残差项的可视化分析
- **性能评估**: 与基准模型的比较评估

## 数据源特化架构

### 概述
系统采用数据源特化架构，将通用数据处理逻辑与特定数据源的处理逻辑分离。每个数据源都有独立的特化模块，包含特征工程和异常检测逻辑，主程序只负责流程控制。

### 架构设计

#### 数据源特化架构
- **主程序**: 负责通用数据预处理流程控制
- **特化模块**: 负责特定数据源的特征工程和异常检测
- **配置驱动**: 通过配置文件定义处理规则

#### 文件结构
```
data/
├── {数据源名称}/
│   ├── {数据源名称}.csv          # 原始数据文件
│   ├── config.json              # 特化配置文件
│   ├── features.py              # 特化特征工程模块
│   ├── anomalies.py             # 特化异常检测模块
│   └── README.md               # 数据源说明文档
├── template/                    # 特化模块开发模板
└── README.md                   # 总体说明
```

### 特化模块接口

#### 特征工程接口
```python
class FeatureEngineer:
    def __init__(self, config):
        self.config = config
    
    def engineer_features(self, data):
        """特征工程主函数"""
        pass
    
    def get_feature_list(self):
        """返回特征列表"""
        pass
```

#### 异常检测接口
```python
class AnomalyDetector:
    def __init__(self, config):
        self.config = config
    
    def detect_anomalies(self, data):
        """异常检测主函数"""
        pass
    
    def get_anomaly_rules(self):
        """返回异常检测规则"""
        pass
```

### 配置文件格式
特化配置文件命名格式：`config.json`

配置文件包含以下内容：
- **字段映射**: 数据字段的映射关系
- **特征工程配置**: 特征工程规则和参数
- **异常检测配置**: 异常检测规则和处理方式
- **数据验证配置**: 数据验证规则和约束
- **业务规则**: 业务逻辑和数据约束

### 配置文件示例
```json
{
  "data_source_name": "user_balance_table",
  "description": "用户余额表数据",
  "field_mapping": {
    "时间字段": "report_date",
    "时间格式": "%Y%m%d",
    "用户ID字段": "user_id",
    "申购金额字段": "total_purchase_amt",
    "赎回金额字段": "total_redeem_amt"
  },
  "feature_engineering": {
    "基础特征": {
      "净资金流": "Net_Flow",
      "总资金流": "Total_Flow"
    },
    "时间特征": {
      "年": "Year",
      "月": "Month"
    }
  },
  "anomaly_detection": {
    "数值异常": {
      "异常值阈值": 2.5,
      "检测字段": ["total_purchase_amt", "total_redeem_amt"]
    },
    "逻辑异常": {
      "负值检测": {
        "启用": true,
        "字段": ["total_purchase_amt", "total_redeem_amt"]
      }
    }
  }
}
```

### 使用方法

#### 1. 添加新数据源
1. 在data文件夹下创建数据源文件夹
2. 将原始数据文件放入文件夹
3. 创建配置文件config.json
4. 实现特化模块features.py和anomalies.py
5. 编写说明文档README.md

#### 2. 使用开发模板
```bash
# 复制模板文件夹
cp -r data/template data/your_data_source_name
# 修改配置文件和相关模块
```

#### 3. 运行数据处理
主程序会自动：
1. 检测数据源
2. 加载对应的特化配置
3. 调用特化模块进行处理
4. 保存处理结果

### 架构优势

1. **模块化**: 每个数据源独立管理
2. **可扩展**: 轻松添加新数据源
3. **可维护**: 特化逻辑与通用逻辑分离
4. **可复用**: 通用预处理逻辑可复用
5. **配置驱动**: 通过配置文件控制处理逻辑

### 支持的字段类型
- **时间字段**: 时间日期字段
- **用户ID字段**: 用户标识字段
- **数值字段**: 各种数值类型字段
- **分类字段**: 分类标签字段
- **自定义字段**: 根据业务需求自定义的字段

## 项目结构

```
Time_Prophet_all/
├── run.py              # 启动文件
├── main.py             # 主程序
├── config.py           # 程序配置
├── start.py            # 启动脚本（自动进入虚拟环境）
├── requirements.txt    # 依赖包列表
├── README.md           # 项目说明
├── script/             # 次要程序文件夹
├── output/             # 生成文件
│   ├── images/         # 图片输出
│   └── data/           # 数据输出
├── data/               # 原始数据
│   ├── user_balance_table/  # 用户余额表数据源
│   │   ├── user_balance_table.csv
│   │   ├── config.json      # 特化配置文件
│   │   ├── features.py      # 特化特征工程模块
│   │   ├── anomalies.py     # 特化异常检测模块
│   │   └── README.md        # 数据源说明文档
│   ├── template/            # 特化模块开发模板
│   └── README.md            # 数据目录说明
├── utils/              # 工具文件夹
├── cache/              # 缓存内容
├── src/                # 主程序的内容分支
│   ├── analysis/       # 数据分析模块
│   │   └── basic_analysis.py  # 基础数据分析
│   ├── prediction/     # 预测模块
│   │   └── arima_predictor.py # ARIMA预测
│   ├── data_processing.py           # 传统数据处理模块
│   └── data_processing_universal.py # 通用数据处理模块
├── temp/               # 临时文件
└── tests/              # 测试文件
```

## 使用说明

### 1. 环境准备
```bash
# 启动项目
python start.py
```

### 2. 首次使用新数据源
1. 将数据文件放入 `data/` 目录
2. 运行基础数据分析功能
3. 系统自动生成数据源配置文件
4. 使用其他功能进行数据分析

### 3. 使用现有数据源
1. 确保数据源配置文件存在
2. 直接运行所需功能
3. 系统自动加载配置文件

### 4. 功能选择
- **基础数据分析**: 数据探索和配置文件生成
- **数据预处理**: 数据清洗和特征工程
- **ARIMA预测**: 时间序列预测

## 配置说明

### 路径配置
- **数据相关路径**
  - `DATA_DIR`: 原始数据目录 (data/)
  - `CACHE_DIR`: 缓存文件目录 (cache/)
  - `TEMP_DIR`: 临时文件目录 (temp/)

- **输出相关路径**
  - `OUTPUT_DIR`: 输出根目录 (output/)
  - `IMAGES_DIR`: 图片输出目录 (output/images/)
  - `OUTPUT_DATA_DIR`: 数据输出目录 (output/data/)

- **程序相关路径**
  - `UTILS_DIR`: 工具模块目录 (utils/)
  - `SRC_DIR`: 源代码目录 (src/)
  - `SCRIPT_DIR`: 脚本目录 (script/)
  - `TESTS_DIR`: 测试目录 (tests/)

### 数据源配置
- **字段映射**: 数据字段与系统标准字段的映射
- **预处理配置**: 数据预处理参数
- **缓存配置**: 字段映射缓存设置

## 错误处理

### 常见问题

#### 1. 缺少数据源配置文件
**错误信息**: "未找到数据源配置文件: xxx_dispose.json"

**解决方案**: 
1. 运行基础数据分析功能
2. 系统会自动生成配置文件

#### 2. 字段映射错误
**错误信息**: "缺少必要的字段映射"

**解决方案**:
1. 检查原始数据文件格式
2. 重新运行基础数据分析
3. 手动修改配置文件

#### 3. 数据格式不匹配
**错误信息**: "数据预处理失败"

**解决方案**:
1. 检查数据文件编码（推荐UTF-8）
2. 检查时间格式是否正确
3. 检查数值字段是否包含非数字字符

## 文件夹说明

- **output/images/**: 存放程序生成的图片文件
- **output/data/**: 存放程序生成的数据文件
- **data/**: 存放原始输入数据和数据源配置文件
- **utils/**: 存放工具函数和辅助模块
- **cache/**: 存放缓存文件，提高程序运行效率
- **src/**: 存放主要业务逻辑代码
- **tests/**: 存放测试代码 